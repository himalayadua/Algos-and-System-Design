# Scalability Intro

> Based on CS75 (Summer 2012) Lecture 9 Scalability Harvard Web Development David Malan
### Why scalability 

- deploying applications on the internet 
- handling large numbers of users

Selecting a web hosting company:
- importance of ensuring accessibility
    - in cases where certain networks block access to specific IP ranges
- using SFTP (Secure File Transfer Protocol) for secure data transmission
    - as opposed to FTP which sends data in the clear

### Types of Hosting: Shared vs. VPS

- Shared hosting 
    - unlimited resources at a low price
    - means contending for resources with other users on the same server
- VPS 
    - provides more privacy and resources
    - but at a higher cost.

### Scaling and Vertical Scaling

- Exploring the concept of scaling a website to handle more users, focusing on vertical scaling:
  
  - Vertical scaling involves increasing resources such as RAM and processor to address performance limitations.
  - Limitations of vertical scaling due to constraints in available technology and financial resources.

### Multi-Core Processing

- Understanding the benefits of multi-core processing in handling multiple tasks simultaneously:
  
  - How multi-core processors enable handling multiple tasks in parallel, improving the server's capacity to handle multiple requests.
  - The impact of multi-core processors on the server's ability to handle more requests per second.

### Conclusion

- The lecture concludes by highlighting the importance of considering different options for scaling websites and the potential for automating the process through services like Amazon EC2.
  
  - Emphasizes the need to plan for unexpected growth and the trade-offs associated with different hosting and scaling options.

### Trend Towards More Computational Resources 

- Humans aren't very good at utilizing available hardware efficiently.
  
  - Most tasks can be done with far fewer computational resources.
  - Software bloat in operating systems and office applications contributes to increased resource usage.
- Trend towards more computational resources has enabled easier division of bigger servers into smaller VPSs.
  
  - Amazon and other cloud providers are able to offer self-service capability due to this trend.

### Types of Hard Drives

- Parallel ATA, IDE, SATA, and SAS are different types of hard drives.
  
  - SATA and SAS are commonly used for hard drives.
  - SAS drives spin faster than SATA drives, providing a speed bump at a higher cost.
- SAS drives are often used for databases, where data needs to be read or written quickly.
  
  - Solid-state drives (SSDs) are even faster than mechanical drives but cost more and have smaller storage capacity.

### Horizontal Scaling vs. Throwing More Resources

- Horizontal scaling involves architecting systems to use cheaper, older hardware and multiple servers rather than relying on top-of-the-line, expensive hardware.
  
  - This approach aims to avoid hitting a ceiling in system performance.
  - Multiple cheaper machines are used instead of a single powerful machine.

### Load Balancing and Server Distribution

- Load balancers are used to distribute inbound HTTP requests across multiple web servers.
  
  - Load balancers decide which backend server to send the request to based on factors like CPU usage and load.
  - Load balancers can optimize performance by directing requests to the least busy server.
- Private IP addresses for backend servers provide privacy and alleviate the scarcity of public IP addresses.
  
  - Load balancers handle the distribution of traffic to backend servers, allowing for efficient use of resources.

### Load Balancing Strategies 

- Load balancing can be achieved through redundant servers with identical content, or through dedicated servers for specific types of content.
  
  - Redundant servers with identical content ensure horizontal scalability but require n times the disk space.
  - Dedicated servers for specific content types can be achieved through different URLs or host names, with a load balancer using HTTP headers to direct requests.

### Round Robin Load Balancing

- Round robin load balancing can be implemented through DNS setup, returning different IP addresses for a host name with each query.
  
  - This approach is simple and uses knowledge from lecture zero but may lead to disproportionate load distribution among servers.
  - Caching can further contribute to uneven server loads due to TTL expiration times associated with DNS responses.

### Limitations of Round Robin Load Balancing

- Round robin load balancing may lead to uneven server loads, as certain servers may receive more demanding requests than others.
  
  - Caching of DNS responses can result in certain servers handling a disproportionate amount of load.
  - Different servers having different session data can break the functionality of PHP-based websites using the session super global.
  - The use of load balancers to make decisions based on server load or other heuristics can help mitigate the risk of uneven server loads.

### Conclusion

- While round robin load balancing is a simple and efficient approach, it may not fully address the issue of uneven server loads and can introduce complexities in maintaining session data for PHP-based websites. Consideration of alternative load balancing strategies and heuristics-based decision making by load balancers can help address these limitations.

### Session Management and Server Load Balancing 

- The speaker discusses a scenario where a website is distributed across multiple servers and the challenges this presents for session management.
  
  - The example is given where a user logs in on one server, but when directed to another server, they are prompted to log in again, causing session cookies to be spread across multiple servers.
  - This leads to issues with e-commerce functionality, such as being unable to check out due to items being stored on different servers.

### Horizontal Scaling and Dedicated Machines

- The discussion moves to the potential solution of using dedicated machines for different server functions, such as PHP, images, and videos, to prevent the session management issue.
  
  - However, concerns are raised about the lack of redundancy and the ability to handle increased traffic.

### Implementing Shared State

- The idea of sharing session states across servers is proposed as a solution, with the suggestion of using a file server connected to all servers to store session data.
  
  - Concerns are raised about the potential weaknesses in network topology and redundancy if the shared state server fails.

### Implementing Redundant Array of Independent Disks (RAID)

- The concept of RAID technology is introduced as a potential solution for improving redundancy and decreasing the probability of downtime.
  
  - Various RAID configurations, including RAID 0, RAID 1, RAID 5, and RAID 6, are explained, highlighting their benefits for data redundancy and fault tolerance.

This comprehensive summary covers the key arguments presented in the provided transcript, outlining the challenges of session management, the potential solutions such as shared state implementation, and the use of RAID technology to enhance redundancy and fault tolerance in server infrastructure.

### Issues with Single Server Setups 

- The speaker highlights the potential issues with single server setups, including the risk of power supply failure, RAM failure, and motherboard failure.
  
  - Redundancy within a single server can help with uptime and robustness, especially in data center servers.
  - Multiple hard drives, RAM banks, and power supplies in computers can provide redundancy and mitigate downtime and data loss.

### Solutions for Redundancy and Load Balancing

- The speaker discusses various technologies and solutions for achieving redundancy and load balancing in server setups.
  
  - Technologies like Fiber Channel (FC) and iSCSI provide fast shared storage across servers.
  - MySQL is suggested as a potential solution for using a separate server to store session objects.
  - Network File System (NFS) is proposed as a protocol for implementing shared file systems.
  - Implementing load balancers, such as Amazon's Elastic Load Balancer, HAProxy, and Linux Virtual Server (LVS), is discussed as a way to balance the load across servers.

### Load Balancing Implementations

- The speaker explains the options for implementing load balancers, including both software and hardware solutions.
  
  - Software options like HAProxy and LVS are mentioned as cost-effective solutions for load balancing.
  - Hardware load balancers from vendors like Barracuda, Cisco, and Citrix are discussed, highlighting their potential overpricing.

### Challenges and Considerations for Load Balancing

- The speaker addresses challenges and considerations related to load balancing, such as caching, replication in databases, and speeding up PHP.
  
  - Caching and replication in databases are identified as areas that need consideration for optimizing server performance.
  - The potential use of cookies to address the problem of sticky sessions and the drawbacks of storing server IDs in cookies are discussed.

### Alternative Load Balancing Approaches

- The speaker explores alternative approaches to load balancing, including storing a random number on the user's computer and having the load balancer remember the association between the random number and the server.
  
  - The alternative approach involving random numbers is presented as a more secure and practical solution for load balancing.

This hierarchical summary covers the key arguments presented in the provided link, addressing issues with single server setups, solutions for redundancy and load balancing, load balancing implementations, challenges, and considerations, as well as alternative load balancing approaches.

### Cookie Handling 

- Load balancers can insert cookies themselves and remember what backend server to send the user to
  
  - If the user disables cookies, the system breaks down
  - Workarounds exist, such as configuring load balancers to insert cookies
- PHP can be optimized for performance through PHP acceleration
  
  - PHP programs can be compiled more efficiently and executed faster
  - PHP accelerators eliminate the discarding of PHP op codes, improving performance

### Caching Techniques

- Static HTML file caching: Craigslist uses static HTML files to store user input and does not regenerate them for every visit
  
  - Performance benefits from serving up static content
  - Downsides include redundancy, difficulty in making changes, and increased disk space usage
- MySQL Query Cache: Enables caching of identical queries, resulting in faster response times for subsequent identical queries
  
  - Provides caching for identically executed queries, improving user navigation experience
- Memcached (MCash): A memory cache that can significantly improve website performance
  
  - Used by companies like Facebook to enhance performance

### Conclusion

- The transcript covers various techniques for improving website performance, including cookie handling, PHP acceleration, and different caching mechanisms.
- Each technique has its trade-offs in terms of performance, storage, and ease of maintenance.
- Understanding and implementing these techniques can significantly impact a website's performance and user experience.

## Use of Memcache in PHP 

- Memcache is used to store data in RAM for quick access.
  
  - "I'd really rather not execute that query more often than I have to. I'd rather execute it once, save the results in RAM, and the next time I need that user, go into the RAM, go into cache to get that user rather than touching the database."
- It is used to improve performance by avoiding frequent database queries and storing data in RAM instead of on disk.
  
  - "So generally, you might want to store something instead of on disk, you want to store it in a table that has indexes so that you can search it more quickly."

### Memcache Server and Performance

- Memcache Server is used to execute queries on data stored in RAM, with the ability to define indexes and keys for faster data retrieval.
  
  - "MySQL is a server, which means it's always running. It's using some RAM so in that case, you have the ability to execute queries on data that's hopefully in RAM."
- Memcache is preferred over traditional databases for its efficient key-value storage mechanism.
  
  - "I want to give you x equals y, and the next time I ask for X, you give me Y, and I want it quick, much faster than a database would return it."

### Memcache Optimization and Garbage Collection

- Memcache has a finite capacity, and it requires garbage collection to manage the space efficiently.
  
  - "So we can essentially expire objects based on when they were put in."
- Objects in the cache are expired based on their last usage, allowing for efficient memory management and reuse of space.
  
  - "The first one in is the first one out if that object has not been needed since."

### Use of Memcache in Facebook

- Facebook uses Memcache extensively to optimize read-heavy operations and reduce the load on databases.
  
  - "Facebook uses things like Memcache quite a bit so that they're not hitting their various databases just to generate your profile. They're instead just getting the results of some previous lookup unless it has since expired."

### MySQL Storage Engine Optimization

- Different storage engines in MySQL, such as InnoDB and MyISAM, offer various features, including support for transactions and table locking.
  
  - "InnoDB supports transactions, whereas MyISAM does not. MyISAM uses locks, which are full table locks."
- Memory and archive storage engines provide options for implementing caching and archiving data efficiently.
  
  - "Memory engine intentionally only stored in RAM, which means if you lose power, server dies, or whatnot, the entire contents of these memory tables will be lost."

### Archive Tables

- Archive tables are slower to query by default, but they are automatically compressed, saving storage space.
  
  - Common use case: log files where data needs to be stored without frequent querying.
  - Sacrifice future performance for long-term disk saving.

### NDB Network Storage Engine

- Used for clustering to address single points of failure in shared storage.

### Replication in MySQL

- Involves a master database for reading and writing, with one or more slave databases to create automatic copies of the master's data.
- Provides redundancy and eliminates the need for backup servers or tapes.

### Master-Slave Topology

- Offers redundancy and quick recovery in case of failure.
  
  - Can promote a slave to become the new master if needed.
- Allows load balancing of queries across multiple servers.

### Faults in Master-Slave Topology

- Single point of failure for write operations.
  
  - Potential downtime for write-heavy operations if the master fails.

### Master-Master Setup

- Allows writing to either server, with data replication between the two.
- Provides redundancy and load balancing without the need for manual intervention.

### Load Balancing and Redundancy

- Utilizing load balancers for redundancy and failover.
  
  - Active-active load balancers constantly listening for connections to backend servers.

### Multi-Tiered Architecture

- Incorporates load balancers and multiple servers for redundancy and fault tolerance.
  
  - Potential single points of failure need to be identified and addressed.

### Conclusion

- The various database topologies and replication methods offer different levels of redundancy, fault tolerance, and performance optimization.
- Each approach has its trade-offs and considerations, requiring careful planning and implementation based on the specific needs of the system.


## Load Balancing and High Availability 

- Load balancers send heartbeats between servers to detect if one server goes offline, allowing for traffic redirection.
  
  - Passive mode servers promote themselves to active if the active server dies.
- Having a single load balancer is a vulnerability as it can take down the entire system if it fails.
- Introducing two load balancers and partitioning can improve fault tolerance and scalability.
  
  - Facebook used partitioning early on to separate servers for different universities.

### Partitioning and Load Balancing

- Partitioning can be used to distribute users based on specific criteria, improving redundancy and load balancing.
  
  - It is common in databases for load balancing based on high-level user information.
- High availability refers to the relationship between servers to ensure continuous service provision in case of failure.
  
  - This concept also applies to databases, ensuring service continuity.

### Sticky Sessions and Database Management

- Sticky sessions can be implemented using load balancers and by storing user sessions in one place.
  
  - This method ensures that the user is directed to the same server for subsequent requests.
- Placing a database on the same server as a web server can lead to data inconsistency and a single point of failure.
  
  - To mitigate this, databases can be connected in a master-master replication setup.

### Security Considerations

- The need for load balancing and high availability should be balanced with security considerations, including firewalling and data consistency.
- Implementing a robust and secure network architecture requires careful consideration of load balancing, partitioning, and database management.

### Network Topology and Load Balancing

- The speaker discusses the need for cross-connectivity and load balancing in the network topology.
  
  - The implication of having to perform load balancing in code due to the components in the system.
  - The challenge of having to change the PHP code when introducing new components in the system.

### Load Balancer Implementation

- The speaker proposes using load balancers to handle requests and distribute features across servers.
  
  - The ability to distribute MySQL queries across database servers using a load balancer.
  - The difficulty of the database performing intelligent load balancing based on last names due to the nature of MySQL traffic.

### Redundancy and Failure Scenarios

- The discussion of single points of failure and the need for redundancy in the system.
  
  - The suggestion of using two switches for redundancy to ensure higher probabilities of uptime and resilience against failure.
  - The need for multiple data centers to mitigate failure scenarios like power outages or network disconnects.

### Global Load Balancing and Failover

- The implementation of load balancing across data centers using DNS-based load balancing.
  
  - The concept of geography-based load balancing to direct traffic to different data centers based on geographical locations.
  - The potential downtime and rerouting of traffic in case of a data center failure.

### Security Considerations

- The types of internet traffic that should be allowed in and out of the network for hosting a LAMP-based website.
  
  - The need for TCP and ENC traffic for website hosting and security considerations.
  - The compromise between security and utility when blocking certain types of traffic.

### Data Center Access and Traffic

- The only allowed traffic into the data center is TCP.
  
  - SSH access is also important, so additional ports may need to be allowed for SSH or SSL-based VPN connections.
- It's essential to consider remote access and connectivity, not only for data centers, but also for web hosting companies or VPS hosting.

### Load Balancer Traffic and Encryption

- Load balancer traffic to web servers can be kept unencrypted to simplify operations within the data center.
  
  - Offloading SSL to the load balancer or a special device is a common practice to keep internal traffic unencrypted.
  - Using expensive load balancers to handle cryptography allows for cheaper web servers without much overhead.

### Traffic Between Web Servers and Databases

- Traffic between web servers and databases typically involves TCP for SQL queries.
  
  - Firewalling capabilities are necessary to control and secure this traffic.
  - Implementing the principle of least privilege is important to restrict unnecessary access and minimize security risks.

### Firewall and Access Control

- Implementing firewalls and access control is crucial for securing the network and preventing unauthorized access.
  
  - Tightening access control ensures that only necessary traffic is allowed, reducing the risk of unexpected behavior or security breaches.
- The principle of least privilege should be applied to limit access and minimize potential security vulnerabilities.